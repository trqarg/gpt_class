{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a44655e-15fb-4479-9d66-ee5d6de5645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import getpass\n",
    "import time\n",
    "import openai\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376f11ed-b7f3-498b-b5c7-7afd01200774",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = getpass.getpass('Enter your openai key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7959a99a-f8d6-433d-b430-daf3cc999837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request(prompt:str) -> str:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        temperature=0.0,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0.52,\n",
    "        presence_penalty=0.5,\n",
    "        stop=[\"11.\"]\n",
    "    )\n",
    "    \n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dacefa-8192-45f3-afe3-181adea37f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"nlp-getting-started/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d204c0c-8737-4023-a4c8-5e33ea316142",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "y_true = []\n",
    "\n",
    "for i in tqdm(range(len(train_df))):\n",
    "    text = train_df.text.iloc[i]\n",
    "    try:\n",
    "        response = send_request(prompt=f\"Predict whether the following tweet is about a real disaster or not. If yes return 1 else return 0. Write nothing else. : {text}\")\n",
    "    except Exception as e:\n",
    "        print('Error: ', e)\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "    try:\n",
    "        prediction.append(int(response[-1]))\n",
    "        y_true.append(train_df.target.iloc[i])\n",
    "    except Exception as e:\n",
    "        print('Error: ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe1444-cac7-48b2-91a9-79ee73e6fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame({\"target\": y_true, \"prediction\": prediction})\n",
    "\n",
    "prediction_df.to_csv(\"prediction_chatgpt_3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d63d1-4334-4372-8667-482d00d8f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sns.set(style='white')\n",
    "cm = confusion_matrix(prediction_df['target'], prediction_df['prediction'], normalize='all', labels=[0, 1])\n",
    "#apply rounding\n",
    "cm = np.around(cm, 2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(np.eye(2), annot=cm, fmt='g', annot_kws={'size': 50},\n",
    "            cmap=sns.color_palette(['tomato', 'palegreen'], as_cmap=True), cbar=False,\n",
    "            yticklabels=['True', 'False'], xticklabels=['True', 'False'], ax=ax)\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.tick_params(labelsize=20, length=0)\n",
    "\n",
    "ax.set_title('Confusion Matrix for GPT-3.5', size=24, pad=20)\n",
    "ax.set_xlabel('Predicted Values', size=20)\n",
    "ax.set_ylabel('Actual Values', size=20)\n",
    "\n",
    "additional_texts = ['(True Positive)', '(False Negative)', '(False Positive)', '(True Negative)']\n",
    "for text_elt, additional_text in zip(ax.texts, additional_texts):\n",
    "    ax.text(*text_elt.get_position(), '\\n' + additional_text, color=text_elt.get_color(),\n",
    "            ha='center', va='top', size=24, weight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('gpt35.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
